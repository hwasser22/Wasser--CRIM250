<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Assignments</title>

<script src="site_libs/header-attrs-2.10/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Wasser-CRIM250</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Journal.html">Assignments</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Assignments</h1>

</div>


<p>This page will contain all the assignments you submit for the class.</p>
<div id="instructions-for-all-assignments" class="section level3">
<h3>Instructions for all assignments</h3>
<p>I want you to submit your assignment as a PDF, so I can keep a record of what the code looked like that day. I also want you to include your answers on your personal GitHub website. This will be good practice for editing your website and it will help you produce something you can keep after the class is over.</p>
<ol style="list-style-type: decimal">
<li><p>Download the Assignment1.Rmd file from Canvas. You can use this as a template for writing your answers. It’s the same as what you can see on my website in the Assignments tab. Once we’re done with this I’ll edit the text on the website to include the solutions.</p></li>
<li><p>On RStudio, open a new R script in RStudio (File &gt; New File &gt; R Script). This is where you can test out your R code. You’ll write your R commands and draw plots here.</p></li>
<li><p>Once you have finalized your code, copy and paste your results into this template (Assignment 1.Rmd). For example, if you produced a plot as the solution to one of the problems, you can copy and paste the R code in R markdown by using the <code>``{r} ```</code> command. Answer the questions in full sentences and Save.</p></li>
<li><p>Produce a PDF file with your answers. To do this, knit to PDF (use Knit button at the top of RStudio), locate the PDF file in your docs folder (it’s in the same folder as the Rproj), and submit that on on Canvas in Assignment 1.</p></li>
<li><p>Build Website, go to GitHub desktop, commit and push. Now your solutions should be on your website as well.</p></li>
</ol>
</div>
<div id="assignment-1" class="section level1">
<h1>Assignment 1</h1>
<p><strong>Collaborators: Theo Athanitis. </strong></p>
<div id="problem-1" class="section level3">
<h3>Problem 1</h3>
<p>Install the datasets package on the console below using <code>install.packages("datasets")</code>. Now load the library.</p>
<pre class="r"><code>#install.packages(&quot;datasets&quot;)
library(datasets)

#install.packages(&quot;knitr&quot;)
library(knitr) #used for knitting to a pdf</code></pre>
<p>Load the USArrests dataset and rename it <code>dat</code>. Note that this dataset comes with R, in the package datasets, so there’s no need to load data from your computer. Why is it useful to rename the dataset?</p>
<pre class="r"><code>dat &lt;- USArrests</code></pre>
<p>It is useful to rename the dataset as it creates a copy of the dataset stored in this newly created variable that can now be modified without changing the original, such as adding a new column for states. Additionally, renaming it can make it easier to call/ reference in later functions.</p>
</div>
<div id="problem-2" class="section level3">
<h3>Problem 2</h3>
<p>Use this command to make the state names into a new variable called State.</p>
<pre class="r"><code>dat$state &lt;- tolower(rownames(USArrests))</code></pre>
<p>This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.</p>
<p>List the variables contained in the dataset <code>USArrests</code>.</p>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;Murder&quot;   &quot;Assault&quot;  &quot;UrbanPop&quot; &quot;Rape&quot;</code></pre>
<p>The variables contained in this dataset are Murder, Assault, UrbanPop, Rape, and state.</p>
</div>
<div id="problem-3" class="section level3">
<h3>Problem 3</h3>
<p>What type of variable (from the DVB chapter) is <code>Murder</code>?</p>
<p>Answer: Quantitative- the values of Murder are numerical values with measurment units as they record the amount of Murder arrests per 100,000 people in each state.</p>
<p>What R Type of variable is it?</p>
<p>Answer: The variable Murder itself is of the type character (as shown using typeof(‘Murder’)), but the Murder values for each state are numeric doubles (as shown with dat[1,1])</p>
<pre class="r"><code>typeof(&#39;Murder&#39;)</code></pre>
<pre><code>## [1] &quot;character&quot;</code></pre>
<pre class="r"><code>typeof(dat[1,1])</code></pre>
<pre><code>## [1] &quot;double&quot;</code></pre>
</div>
<div id="problem-4" class="section level3">
<h3>Problem 4</h3>
<p>What information is contained in this dataset, in general? What do the numbers mean?</p>
<p>Answer: This dataset contains data on violent crime rates and urban area populations for each of the 50 states in 1973. The variables and their values contained are 1. the number of murder arrests per 100,000 people, 2. the number of assault arrests per 100,000 people, 3. the percentage of the population that lives in an urban environment, and 4. the number of rape arrests per 100,000 people for every US state.</p>
</div>
<div id="problem-5" class="section level3">
<h3>Problem 5</h3>
<p>Draw a histogram of <code>Murder</code> with proper labels and title.</p>
<pre class="r"><code>hist(dat$Murder, main=&quot;Histogram of Murder&quot;, xlab=&quot;Murder arrests (per 100,000)&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="problem-6" class="section level3">
<h3>Problem 6</h3>
<p>Please summarize <code>Murder</code> quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?</p>
<pre class="r"><code>mean(dat$Murder)</code></pre>
<pre><code>## [1] 7.788</code></pre>
<pre class="r"><code>median(dat$Murder)</code></pre>
<pre><code>## [1] 7.25</code></pre>
<pre class="r"><code>quantile(dat$Murder)</code></pre>
<pre><code>##     0%    25%    50%    75%   100% 
##  0.800  4.075  7.250 11.250 17.400</code></pre>
<p>The mean of Murder is 7.788 and the median of Murder is 7.25. Mean is the sum of all of the states’ murder arrests per 100,000 people divided by 50 (the number of states) also known as the average, while median is the middle value, where half of the value are greater than and half are less than the median, of the states’ murder arrests per 100,000 people values. A quartile is one of three values which divide the dataset into four equal divisions. R likely only provides the 1st and 3rd quartiles (although I did not find a quartile function that operates this way and instead utilized the quantile function) as the 2nd quartile is the same as the median, therefore making the 1st and 3rd much more useful as they are more likely still unknown in comparison to the 2nd quartile when utilizing this function.</p>
</div>
<div id="problem-7" class="section level3">
<h3>Problem 7</h3>
<p>Repeat the same steps you followed for <code>Murder</code>, for the variables <code>Assault</code> and <code>Rape</code>. Now plot all three histograms together. You can do this by using the command <code>par(mfrow=c(3,1))</code> and then plotting each of the three.</p>
<pre class="r"><code>par(mfrow=c(3,1))
hist(dat$Murder, main=&quot;Histogram of Murder&quot;, xlab=&quot;Murder arrests (per 100,000)&quot;, ylab=&quot;Frequency&quot;)
hist(dat$Assault, main=&quot;Histogram of Assault&quot;, xlab=&quot;Assault arrests (per 100,000)&quot;, ylab=&quot;Frequency&quot;)
hist(dat$Rape, main=&quot;Histogram of Rape&quot;, xlab=&quot;Rape arrests (per 100,000)&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-8-1.png" width="480" /></p>
<p>What does the command par do, in your own words (you can look this up by asking R <code>?par</code>)?</p>
<p>Answer: The par command is used to modify the manner in which graphs are displayed by finding, modifying, or setting the parameters of graphs. One functionality of par includes the ability to show multiple graphs together in the same graphic as shown here. In this instance, the mfrow=c(3,1) parameter is a vector with subplots of 1 in length (row) and 3 in depth (column), to create the stacked graphs the function above produces.</p>
<p>What can you learn from plotting the histograms together?</p>
<p>Answer: By plotting the histograms together, it is easier to see the distributional differences between the different variables. By organizing the histograms this way, it can be seen that the frequency by state for murder and rape arrests per 100,000 people are skewed to the left, while the frequency of assult arrests by state are more evenly distributed. While these histograms are not directly comparable because of their different scales, skewdness can still be recognized across them and this display makes it easier to recognize.</p>
</div>
<div id="problem-8" class="section level3">
<h3>Problem 8</h3>
<p>In the console below (not in text), type <code>install.packages("maps")</code> and press Enter, and then type <code>install.packages("ggplot2")</code> and press Enter. This will install the packages so you can load the libraries.</p>
<p>Run this code:</p>
<pre class="r"><code>library(&#39;maps&#39;) 
library(&#39;ggplot2&#39;) 


ggplot(dat, aes(map_id=state, fill=Murder)) + 
  geom_map(map=map_data(&quot;state&quot;)) + 
  expand_limits(x=map_data(&quot;state&quot;)$long, y=map_data(&quot;state&quot;)$lat)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-9-1.png" width="720" /></p>
<p>What does this code do? Explain what each line is doing.</p>
<p>Answer: First, the libraries for maps and ggplots are loaded. Next the ggplot function is called with first the parameter of dat as the dataset for the plot. The next set of parameters is for the aesthetic mapping for the plot basing the map_id for the values on the state variables and the fill/ color of that fill based on the Murder variable value for that representative map_id, as just defined. The fifth line further modifies the aesthetic mapping by defining the map for establishing the coordinate locations to display/divide the states and their fills. Lastly, the sixth line further modifies the aesthetic mapping by defining the x and y limits of this graphic based on the x and y limits from the state positional variables using their latitude and longitudinal values to ensure that all values are displayed.</p>
<p>These last three lines together are creating a map of the Murder arrests per 100,000 people for each state by scaling the color of each state on a map of the United States to represent the degree of this amount in comparion to the other US states.</p>
</div>
</div>
<div id="assignment-2" class="section level1">
<h1>Assignment 2</h1>
<div id="problem-1-load-data" class="section level3">
<h3>Problem 1: Load data</h3>
<p>Set your working directory to the folder where you downloaded the data.</p>
<pre class="r"><code>#setwd(&quot;/Users/hwasser/Documents/Penn/4 Fourth Year/CRIM 250/Assignment 2&quot;)</code></pre>
<p>Read the data</p>
<pre class="r"><code>dat &lt;- read.csv(file = &#39;dat.nsduh.small.1.csv&#39;)</code></pre>
<p>What are the dimensions of the dataset?</p>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 171   7</code></pre>
<p>There are 171 rows (excluding the row containing the column names) and 7 columns</p>
</div>
<div id="problem-2-variables" class="section level3">
<h3>Problem 2: Variables</h3>
<p>Describe the variables in the dataset.</p>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;mjage&quot;     &quot;cigage&quot;    &quot;iralcage&quot;  &quot;age2&quot;      &quot;sexatract&quot; &quot;speakengl&quot;
## [7] &quot;irsex&quot;</code></pre>
<p>• mjage is the age that respondents reported first trying marijuana or hashish • cigage is the age that respondents reported first started smoking cigarettes everyday • iralcage is the age that respondents reported first trying alcohol • age2 is a variable that represents an age bracket corresponding to the consistency checked age from respondents reported age from the beginning of the survey, end of the survey, and their birth date • sexatract is a variable representing categories of sexual attraction ranging from only attraction to the opposite sex to only attraction to the same sex reported by the respondent • speakengl is a variable that represents how well a respondent reports their ability to speak English with categories of very well, well, not well, and not at all • irsex is a variable that represents the respondents reported gender with 1 as male and 2 as female</p>
<p>What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data?</p>
<p>This dataset is a sample from the 2019 National Survey for Drug Use and Health that focuses on the data collected on tobacco, alcohol, and drug use in the United States, along with the demographic information for these respondents, and is a stratified random sample. This data is collected by the Substance Abuse and Mental Health Services Administration (SAMHSA), which is an agency in the U.S. Department of Health and Human Services (HHS), in order to provide support for prevention/ treatment programs, monitor substance use trends in the United States, and ultimately inform public health policy by estimating the need for treatment in the US based on this data.</p>
</div>
<div id="problem-3-age-and-gender" class="section level3">
<h3>Problem 3: Age and gender</h3>
<p>What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.</p>
<pre class="r"><code>table(dat$age2)</code></pre>
<pre><code>## 
##  4  6  7  8  9 10 11 12 13 14 15 16 17 
##  2  1  1  2  7  3  6  7 27 16 62 24 13</code></pre>
<pre class="r"><code>hist(dat$age2, main = &quot;Histogram of Age&quot;, xlab = &quot;Age&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>This histogram shows a clear skew to the right with distribution with the largest number of respondents being between 39-45 years old, with very few respondents under the age of 20 years old.</p>
<p>Do you think this age distribution representative of the US population? Why or why not?</p>
<p>I do not believe that this age distribution is representative of the US population as there were no respondents (0%) being under 15 years of age and only 7.6% of respondents being 65 or older. The actual US population is 18.37% for ages 0-14 and 16.63% for 65 and older, which is clearly not represented by the respondents in this survey, however including the younger demographic would not be useful in this data collection as they would likely be unable to provide answers to the majority of these questions about drug and alcohol use. Furthermore, this sample has large peaks, as shown my the high frequency for the 39-45 year old respondents, however the US population distribution is much more consistent in this middle section with no peaks.</p>
<p>Is the sample balanced in terms of gender? If not, are there more females or males?</p>
<pre class="r"><code>table(dat$irsex)</code></pre>
<pre><code>## 
##  1  2 
## 91 80</code></pre>
<p>There are 91 respondents for 1 and 80 respondents for 2, so there are more males than females in the sample.</p>
<p>Use this code to draw a stacked bar plot to view the relationship between sex and age. What can you conclude from this plot?</p>
<pre class="r"><code>tab.agesex &lt;- table(dat$irsex, dat$age2)
barplot(tab.agesex,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;Age category&quot;, ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.agesex),
        beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>From this stacked bar graph, it appears that there seems to be a fairly even split between male and female respondents on average for the age categories. Looking at it more carefully though, it can be seen that the bins 6, 7, 14, 16, and 17 have at least slightly more male respondents than female respondents, while bins 8 and 9 have more female than male respondents.</p>
</div>
<div id="problem-4-substance-use" class="section level3">
<h3>Problem 4: Substance use</h3>
<p>For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier?</p>
<pre class="r"><code>par(mfrow=c(3,1))
hist(dat$mjage)
hist(dat$cigage)
hist(dat$iralcage)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code>table(dat$mjage)</code></pre>
<pre><code>## 
##  7  9 10 11 12 13 14 15 16 17 18 19 20 21 22 25 27 30 32 33 35 
##  1  4  2  7 10 16 22 22 28 16 16  4  7  6  2  2  2  1  1  1  1</code></pre>
<pre class="r"><code>table(dat$cigage)</code></pre>
<pre><code>## 
## 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 27 35 45 50 
##  1  1  3 10 10 25 25 20 31 11 10  6  5  4  1  4  1  1  1  1</code></pre>
<pre class="r"><code>table(dat$iralcage)</code></pre>
<pre><code>## 
##  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23 
##  2  1  2  1  4  4 19 21 22 19 26 12 23  6  2  6  1</code></pre>
<p>It appears that of the three substances, individuals tend to try alcohol earliest. While the early age of use is similar across these substances, alcohol has the youngest responses with 2 at age 5, in comparison to 7 and 10 for cigarettes and marijuana, as well as having similar numbers of respondents for the following years as marijuana, demonstrating these are not pure outliers, making it the substance that individuals tend to use earlier. For each substance, the highest reported age frequency was 16, demonstrating the early similarity between them, but alcohol has more respondents on the younger end of this spectrum than marijuana or cigarettes, as well as not having any respondents greater than 23, in comparison to 35 and 50 for the other substances.</p>
</div>
<div id="problem-5-sexual-attraction" class="section level3">
<h3>Problem 5: Sexual attraction</h3>
<p>What does the distribution of sexual attraction look like? Is this what you expected?</p>
<pre class="r"><code>table(dat$sexatract)</code></pre>
<pre><code>## 
##   1   2   3   4   5   6  99 
## 136  16   9   3   3   1   3</code></pre>
<p>The distribution of sexual attraction is strongly skewed to the left towards only attraction to the opposite sex. Honestly this is not what I expected, as I would say that at least a 30-40% of the people I know in my generation identify as not straight, but I should have recognized the generational divide and as the survey respondents ages are distributed more on the older side, this should have been more expected. When comparing these numbers to national surveys on sexual attraction, especially ones with larger amounts of older</p>
<p>What is the distribution of sexual attraction by gender?</p>
<pre class="r"><code>table(dat$sexatract, dat$irsex)</code></pre>
<pre><code>##     
##       1  2
##   1  82 54
##   2   3 13
##   3   0  9
##   4   1  2
##   5   2  1
##   6   1  0
##   99  2  1</code></pre>
<p>When comparing sexual attraction by gender, it appears that there are more women who identify as mostly attracted to the same sex and equally attracted to males and females than there are male respondents for either of these categories. Compensating for these differences, there are more males that responded that they are only attracted to the opposite sex than females.</p>
</div>
<div id="problem-6-english-speaking" class="section level3">
<h3>Problem 6: English speaking</h3>
<p>What does the distribution of English speaking look like in the sample? Is this what you might expect for a random sample of the US population?</p>
<pre class="r"><code>table(dat$speakengl)</code></pre>
<pre><code>## 
##   1   2   3 
## 161   8   2</code></pre>
<p>The vast majority of respondents report speaking English very well with 161 respondents, and then only 8 respondents for well and 2 for not well. This is consistent with what would be expected from a random sample of the US population. The US census reports that only 8.6% of the population “does not have a firm grasp of the English language”, making the 94% of respondents in the survey stating very well is consistent with this data.</p>
<p>Are there more English speaker females or males?</p>
<pre class="r"><code>table(dat$speakengl, dat$irsex)</code></pre>
<pre><code>##    
##      1  2
##   1 84 77
##   2  7  1
##   3  0  2</code></pre>
<p>There are more English speakers that are male with 91 responding either very well or well, with only 78 females responding to these categories, however this can be accounted for by the fact that more males responded to the survey in general. 100% of male respondents reported that they spoke English very well or well, and 97.5% of female male respondents reported that they spoke English very well or well.</p>
</div>
</div>
<div id="midterm" class="section level1">
<h1>Midterm</h1>
<pre class="r"><code>#setwd(&quot;/Users/hwasser/Documents/Penn/4 Fourth Year/CRIM 250/Exam 1&quot;)
dat &lt;- read.csv(file = &#39;fatal-police-shootings-data.csv&#39;)</code></pre>
<div id="problem-1-10-points" class="section level3">
<h3>Problem 1 (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>Describe the dataset. This is the source: <a href="https://github.com/washingtonpost/data-police-shootings" class="uri">https://github.com/washingtonpost/data-police-shootings</a> . Write two sentences (max.) about this.</li>
</ol>
<p>This dataset contains recordings of all fatal shootings by police in the United States since January 1st 2015 to the present (last updated 4 days ago) compiled by the Washington Post from news reports, law eenforcment sites, social media, and independent databases. For each fatal shooting, information about the victim and the manner in which they were treated by police is included, such as demographic information, whether or not the officer was wearing a body camera, the location, and the ‘threat factor’.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>How many observations are there in the data frame?</li>
</ol>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 6594   17</code></pre>
<p>There are 6594 observations of 17 variables.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Look at the names of the variables in the data frame. Describe what “body_camera”, “flee”, and “armed” represent, according to the codebook. Again, only write one sentence (max) per variable.</li>
</ol>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>##  [1] &quot;id&quot;                      &quot;name&quot;                   
##  [3] &quot;date&quot;                    &quot;manner_of_death&quot;        
##  [5] &quot;armed&quot;                   &quot;age&quot;                    
##  [7] &quot;gender&quot;                  &quot;race&quot;                   
##  [9] &quot;city&quot;                    &quot;state&quot;                  
## [11] &quot;signs_of_mental_illness&quot; &quot;threat_level&quot;           
## [13] &quot;flee&quot;                    &quot;body_camera&quot;            
## [15] &quot;longitude&quot;               &quot;latitude&quot;               
## [17] &quot;is_geocoding_exact&quot;</code></pre>
<pre class="r"><code>#table(dat$body_camera)
#table(dat$flee)
#table(dat$armed)</code></pre>
<p>body_camera is a binary variable that is True when news reports document that the officer was wearing a body camera and may have recorded at least some part of the interaction. The flee variable describes the manner in which a victim was moving away from the officers, if at all, and the responses are either ‘Foot’, ‘Car’, ‘Not fleeing’, ‘Other’, or blank. The armed variable describes if the victim possessed an object that the officer believed could harm others with responses of ‘undetermined’ (it is not know whether or not the victim was armed), ‘unknown’ (the victim possessed an object but what it was is not known), ‘unarmed’, or the identifier of the object itself.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>What are three weapons that you are surprised to find in the “armed” variable? Make a table of the values in “armed” to see the options.</li>
</ol>
<pre class="r"><code>table(dat$armed)</code></pre>
<pre><code>## 
##                                                   air conditioner 
##                              207                                1 
##                       air pistol                   Airsoft pistol 
##                                1                                3 
##                               ax                         barstool 
##                               24                                1 
##                     baseball bat          baseball bat and bottle 
##                               20                                1 
## baseball bat and fireplace poker           baseball bat and knife 
##                                1                                1 
##                            baton                           BB gun 
##                                6                               15 
##               BB gun and vehicle                     bean-bag gun 
##                                1                                1 
##                      beer bottle                       binoculars 
##                                3                                1 
##                     blunt object                           bottle 
##                                5                                1 
##                    bow and arrow                       box cutter 
##                                1                               13 
##                            brick              car, knife and mace 
##                                2                                1 
##                          carjack                            chain 
##                                1                                3 
##                        chain saw                         chainsaw 
##                                2                                1 
##                            chair              claimed to be armed 
##                                4                                1 
##               contractor&#39;s level                   cordless drill 
##                                1                                1 
##                         crossbow                          crowbar 
##                                9                                5 
##                        fireworks                         flagpole 
##                                1                                1 
##                       flashlight                      garden tool 
##                                2                                2 
##                      glass shard                          grenade 
##                                4                                1 
##                              gun                      gun and car 
##                             3798                               12 
##                    gun and knife                  gun and machete 
##                               22                                3 
##                    gun and sword                  gun and vehicle 
##                                1                               17 
##              guns and explosives                           hammer 
##                                3                               18 
##                       hand torch                          hatchet 
##                                1                               14 
##                  hatchet and gun                         ice pick 
##                                2                                1 
##                incendiary device                            knife 
##                                2                              955 
##                knife and vehicle                 lawn mower blade 
##                                1                                2 
##                          machete                  machete and gun 
##                               51                                1 
##                     meat cleaver                  metal hand tool 
##                                6                                2 
##                     metal object                       metal pipe 
##                                5                               16 
##                       metal pole                       metal rake 
##                                4                                1 
##                      metal stick                       microphone 
##                                3                                1 
##                       motorcycle                         nail gun 
##                                1                                1 
##                              oar                       pellet gun 
##                                1                                3 
##                              pen                     pepper spray 
##                                1                                2 
##                         pick-axe                    piece of wood 
##                                4                                7 
##                             pipe                        pitchfork 
##                                7                                2 
##                             pole                   pole and knife 
##                                3                                2 
##                  railroad spikes                             rock 
##                                1                                7 
##                    samurai sword                         scissors 
##                                4                                9 
##                      screwdriver                     sharp object 
##                               16                               14 
##                           shovel                            spear 
##                                7                                2 
##                          stapler              straight edge razor 
##                                1                                5 
##                            sword                            Taser 
##                               23                               34 
##                        tire iron                       toy weapon 
##                                4                              226 
##                          unarmed                     undetermined 
##                              421                              188 
##                   unknown weapon                          vehicle 
##                               82                              213 
##                  vehicle and gun              vehicle and machete 
##                                8                                1 
##                    walking stick                       wasp spray 
##                                1                                1 
##                           wrench 
##                                1</code></pre>
<p>Flashlight, wasp spray, and ice pick.</p>
</div>
<div id="problem-2-10-points" class="section level3">
<h3>Problem 2 (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>Describe the age distribution of the sample. Is this what you would expect to see?</li>
</ol>
<pre class="r"><code>hist(dat$age)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code>table(dat$age)</code></pre>
<pre><code>## 
##   6  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30 
##   2   1   2   3  16  35  56 109  98 105 124 138 148 179 216 188 217 194 204 204 
##  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50 
## 223 207 205 209 196 186 183 164 165 140 142 112 120 101 126 109 115 110 103  95 
##  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70 
##  89  82  78  71  67  72  58  56  66  47  44  45  35  25  28  19  23  16  17  16 
##  71  72  73  74  75  76  77  78  79  80  81  82  83  84  86  88  89  91 
##  12   7   7   6   5  12   5   1   4   5   3   2   3   4   2   1   1   2</code></pre>
<p>The age distribution is skewed slightly to the right, with the largest group of victims being in their mid-late 20s to early-mid 30s. There are very few victims below the age of 15 and above the age of 71, however the tail on the right is longer. This is what I expected to see as the largest frequency shown here are part of the population that has the largest interaction with the police, however I was a little surprised by how few older teenage fatal shootings there were based on the increased involvement in crime and dangerous behavior that is demonstrated by this age group. I was also surprised by how high some of the values were on the right side of the peak.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.</li>
</ol>
<pre class="r"><code>summary(dat$age)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    6.00   27.00   35.00   37.12   45.00   91.00     308</code></pre>
<pre class="r"><code>median(dat$age, na.rm = TRUE)</code></pre>
<pre><code>## [1] 35</code></pre>
<p>As the age distribution is not symmetrical, the mean and median do not coincide. In this case, the distribution is skewed so the mean will be further towards the the tail, while the median will better represent the central tendency of the data. The median of age is 35 (excluding observations where age was not included).</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe the gender distribution of the sample. Do you find this surprising?</li>
</ol>
<pre class="r"><code>table(dat$gender)</code></pre>
<pre><code>## 
##         F    M 
##    3  293 6298</code></pre>
<p>There were 6298 male victims and 293 female victims, making almost 95.5% of all victims of police shooting being male. While I expected there to be significantly more male than female victims based on the gender division for criminal activity especially for violent crimes, however I did not expect the difference to be this large.</p>
</div>
<div id="problem-3-10-points" class="section level3">
<h3>Problem 3 (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?</li>
</ol>
<pre class="r"><code>table(dat$body_camera)</code></pre>
<pre><code>## 
## False  True 
##  5684   910</code></pre>
<p>According to news reports, in only 910 of the incidents, the police officers had a body camera. Therefore, in only 16% of all fatal shootings by police, the police had a body camera. I am surprised that it is so low, as the vast majority of officers that I see on a day-to-day basis are wearing them, but I have to imagine that much of my perception about body-worn cameras is based on where I have lived and the policies in these cities.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>In how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?</li>
</ol>
<pre class="r"><code>table(dat$flee)</code></pre>
<pre><code>## 
##                     Car        Foot Not fleeing       Other 
##         491        1058         845        3952         248</code></pre>
<p>In 1058 cases the victim was fleeing by car, in 845 cases the victim was fleeing on foot, in 3952 cases the victim was not fleeing, in 248 cases the value was listed as Other, and no response was recorded for 491 cases. Excluding the 491 cases and 248 responses for ‘Other’, out of the remaining 5855 cases only 1903 cases the victim flee-ed in. Therefore, in 32.5% of cases the victim flee-ed (not including observations where the response was blank or Other due to lack of information). This statistic is a little suprising to me as I expected the percentage of victims that were fleeing to be higher as it does have some relation to the threat they pose to the public, especially if they are armed.</p>
</div>
<div id="problem-4-10-points" class="section level3">
<h3>Problem 4 (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>Describe the relationship between the variables “body camera” and “flee” using a stacked barplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the options for “flee”, each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<pre class="r"><code>barplot(table(dat$body_camera, dat$flee), main = &quot;Relationship between body camera and flee&quot;, xlab = &quot;Flee type&quot;, ylab = &quot;Frequency&quot;, legend = TRUE)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>From this stacked barplot, there does not appear to be a significant relationship between the officer wearing a body-worn camera and whether/ how a victim flees. It shows that in all cases of fleeing and not fleeing, officers are much more likely to not be wearing a body-worn camera.While it appears that those not fleeing and the officer is wearing a body camera vs those fleeing and the officer wearing a body camera is larger, in actuality these ratios are very similar and just looks larger because of the size of the column.</p>
</div>
<div id="extra-credit-10-points" class="section level3">
<h3>Extra credit (10 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>What does this code tell us?</li>
</ol>
<pre class="r"><code>mydates &lt;- as.Date(dat$date)
head(mydates)
#tail(mydates)
(mydates[length(mydates)] - mydates[1])</code></pre>
<p>This code first modifies the character representation of the date provided in the table and classifies it as an object of the Date class. The head function is used to show the first couple values in this table of format-modified dates. Lastly, the difference between the final date (same as table[length(table)]) included in the table and the first date in the table is found to determine the number of days between the two. This shows that this data represents 2458 days fro January 2nd 2015 to September 25 2021.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>On Friday, a new report was published that was described as follows by The Guardian: “More than half of US police killings are mislabelled or not reported, study finds.” Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?</li>
</ol>
<p>As police killings reflect poorly on police officers and as it is their responsibility to report them, there is a motivation and ability to not accurately report this data so that it presents a more positive view of the police/ their abilities. Additionally, it is possible that these incidents are being intentionally mislabled to better a precincts statistics or simply due to error caused by excessive movement of paperwork and lack of a streamlined process.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Regarding missing values in problem 4, do you see any? If so, do you think that’s all that’s missing from the data?</li>
</ol>
<p>For the flee variable, there are 491 responses that left this column blank. I would expect there to be more missing values in the dataset. Other missing values include 3 victims that do not have a gender listed and 752 victims whose race value was missing.</p>
</div>
</div>
<div id="assignment-3" class="section level1">
<h1>Assignment 3</h1>
<p><strong>Collaborators: Theo</strong>.</p>
<p>This assignment is due on Canvas on Wednesday 10/27/2021 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<p>Submit your responses as either an HTML file or a PDF file on Canvas. Also, please upload it to your website.</p>
<p>Save the file (found on Canvas) crime_simple.txt to the same folder as this file (your Rmd file for Assignment 3).</p>
<p>Load the data.</p>
<pre class="r"><code>library(readr)
library(knitr)
dat.crime &lt;- read_delim(&quot;crime_simple.txt&quot;, delim = &quot;\t&quot;)</code></pre>
<p>This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given.</p>
<p>Here is the codebook:</p>
<p>R: Crime rate: # of offenses reported to police per million population</p>
<p>Age: The number of males of age 14-24 per 1000 population</p>
<p>S: Indicator variable for Southern states (0 = No, 1 = Yes)</p>
<p>Ed: Mean of years of schooling x 10 for persons of age 25 or older</p>
<p>Ex0: 1960 per capita expenditure on police by state and local government</p>
<p>Ex1: 1959 per capita expenditure on police by state and local government</p>
<p>LF: Labor force participation rate per 1000 civilian urban males age 14-24</p>
<p>M: The number of males per 1000 females</p>
<p>N: State population size in hundred thousands</p>
<p>NW: The number of non-whites per 1000 population</p>
<p>U1: Unemployment rate of urban males per 1000 of age 14-24</p>
<p>U2: Unemployment rate of urban males per 1000 of age 35-39</p>
<p>W: Median value of transferable goods and assets or family income in tens of $</p>
<p>X: The number of families per 1000 earning below 1/2 the median income</p>
<p>We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related.</p>
<div id="how-many-observations-are-there-in-the-dataset-to-what-does-each-observation-correspond" class="section level3">
<h3>1. How many observations are there in the dataset? To what does each observation correspond?</h3>
<pre class="r"><code>dim(dat.crime)</code></pre>
<pre><code>## [1] 47 14</code></pre>
<p>There are 47 observations of 14 variables. Each observation corresponds with 1 of the 47 US states represented in this data.</p>
</div>
<div id="draw-a-scatterplot-of-the-two-variables.-calculate-the-correlation-between-the-two-variables.-can-you-come-up-with-an-explanation-for-this-relationship" class="section level3">
<h3>2. Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?</h3>
<pre class="r"><code>plot(dat.crime$Ed, dat.crime$R, main=&quot;Relationship between the Crime Rate and Average Education&quot;,
    xlab=&quot;Mean of years of schooling x 10 for persons of age 25 or older&quot;, ylab=&quot;Number of offenses reported to police per million population&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-35-1.png" width="576" /></p>
<pre class="r"><code>cor(dat.crime$Ed, dat.crime$R)</code></pre>
<pre><code>## [1] 0.3228349</code></pre>
<p>There is a correlation of 0.3228349.</p>
<p>While I would have predicted that with an increase in education level that there would be a reduction in crimes, as with higher levels of education there are more and higher paying work opportunities, as well as greater exposure to support groups through the educational system which are both correlated with reducing crime, however this data is looking specifically at crimes reported and not just crimes that occurred. This correlation shows a moderate positive correlation between mean years of schooling and number of crimes reported. This could be attributed to individuals with more years of education being able to better identify criminal activity and know how to properly report that information to the police without fear of retribution for example, as well as organizations within higher education utilizing advocacy groups to inform students on crime reporting, intervention, and communitty-police relashonships.</p>
</div>
<div id="regress-reported-crime-rate-y-on-average-education-x-and-call-this-linear-model-crime.lm-and-write-the-summary-of-the-regression-by-using-this-code-which-makes-it-look-a-little-nicer-r-evalfalse-kablesummarycrime.lmcoef-digits-2." class="section level3">
<h3>3. Regress reported crime rate (y) on average education (x) and call this linear model <code>crime.lm</code> and write the summary of the regression by using this code, which makes it look a little nicer <code>{r, eval=FALSE} kable(summary(crime.lm)$coef, digits = 2)</code>.</h3>
<pre class="r"><code>crime.lm &lt;- lm(dat.crime$R ~ dat.crime$Ed, data = dat.crime)
#plot(crime.lm)
summary(crime.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat.crime$R ~ dat.crime$Ed, data = dat.crime)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -60.061 -27.125  -4.654  17.133  91.646 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  -27.3967    51.8104  -0.529   0.5996  
## dat.crime$Ed   1.1161     0.4878   2.288   0.0269 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 37.01 on 45 degrees of freedom
## Multiple R-squared:  0.1042, Adjusted R-squared:  0.08432 
## F-statistic: 5.236 on 1 and 45 DF,  p-value: 0.02688</code></pre>
<pre class="r"><code>#kable(summary(crime.lm)$coef, digits = 2)</code></pre>
</div>
<div id="are-the-four-assumptions-of-linear-regression-satisfied-to-answer-this-draw-the-relevant-plots.-write-a-maximum-of-one-sentence-per-assumption." class="section level3">
<h3>4. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)</h3>
<pre class="r"><code>#Linearity Assumption:
plot(dat.crime$Ed, crime.lm$residuals, main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Education&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=1)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-37-2.png" width="672" /></p>
<pre class="r"><code>#Independence Assumption: using Residuals vs. x plotted above
plot(dat.crime$Ed, dat.crime$R, main=&quot;Relationship between the Crime Rate and Average Education&quot;,
    xlab=&quot;Mean of years of schooling x 10 for persons of age 25 or older&quot;, ylab=&quot;Number of offenses reported to police per million population&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-37-3.png" width="672" /></p>
<pre class="r"><code>#Equal Variance Assumption/ Homoscedasticity:
plot(crime.lm, which=3)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-37-4.png" width="672" /></p>
<pre class="r"><code>#Normal Population Assumption:
plot(crime.lm, which=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-37-5.png" width="672" /></p>
<pre class="r"><code>#plot(crime.lm, which=5)</code></pre>
<p>Linearity Assumption: This assumption is met as the Residuals vs. X plot has a horizontal direction and has no apparent patterns, as well as the Residuals vs. Fitted shows a relatively flat line for the average value of the residuals at each value of fitted value meaning there is not a non-linear trend to the residuals.</p>
<p>Independence Assumption: This assumption is met as the Residuals vs. X plot has no apparent patterns and there is not a time series component in this data.</p>
<p>Equal Variance Assumption/ Homoscedasticity: This assumption is met as the scatter plot of education vs. reported crime as there is no apparent tendency for the variations to grow or shrink in any part of the plot and there are no significant trends shown by the line in the scale-location plot showing that the errors have fairly constant variance.</p>
<p>Normal Population Assumption: This assumption is not met as the normal Q-Q plot does not show that the residuals are not normally distributive and instead have significant abnormal distributions of the tails.</p>
<p>All of these assumptions are based on a fairly small sample as there are only 47 observations so for the first three assumptions, I have determined that they are normal enough to their respective values as listed above to have the assumptions met. However, the final normal population assumption is not met due to the significant deviation of the tails despite the small sample size.</p>
</div>
<div id="is-the-relationship-between-reported-crime-and-average-education-statistically-significant-report-the-estimated-coefficient-of-the-slope-the-standard-error-and-the-p-value.-what-does-it-mean-for-the-relationship-to-be-statistically-significant" class="section level3">
<h3>5. Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?</h3>
<pre class="r"><code>summary(crime.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat.crime$R ~ dat.crime$Ed, data = dat.crime)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -60.061 -27.125  -4.654  17.133  91.646 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  -27.3967    51.8104  -0.529   0.5996  
## dat.crime$Ed   1.1161     0.4878   2.288   0.0269 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 37.01 on 45 degrees of freedom
## Multiple R-squared:  0.1042, Adjusted R-squared:  0.08432 
## F-statistic: 5.236 on 1 and 45 DF,  p-value: 0.02688</code></pre>
<p>The coefficient of the slope is 1.1161. The standard error is 0.4878. The p-value is 0.02688.</p>
<p>This relationship between reported crime and average education is statistically significant as the p-value of 0.02688 is less than 5%, but given that the normal population assumption was not satisfied, the actual statistical significance may be less than what is represented here by the p-value. A relationship is statistically significant when it is not likely to occur simply because of random chance (when the null hypothesis is true) but instead due to specific cause.</p>
</div>
<div id="how-are-reported-crime-and-average-education-related-in-other-words-for-every-unit-increase-in-average-education-how-does-reported-crime-rate-change-per-million-per-state" class="section level3">
<h3>6. How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?</h3>
<p>For every unit increase in average education, reported crime rate per million increased by 1.1161 per state.</p>
</div>
<div id="can-you-conclude-that-if-individuals-were-to-receive-more-education-then-crime-will-be-reported-more-often-why-or-why-not" class="section level3">
<h3>7. Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?</h3>
<p>We are not able to make this conclusion that if individuals were to receive more education that crime will be reported more often. Simply put, correlation does not imply causation. There may be many other outside factors effecting the relationship found here such as:</p>
<p>States with larger budgets that invest more into government and social programs- states that have higher mean education levels because of increased funding into the education system may also having higher funding for police initiatives such as building more streamlined, online reporting portals for crimes, which would likely increase the likelihood that crimes are reported due to the easier process which has no relation to the average education level of its citizens.</p>
</div>
</div>
<div id="midterm-2" class="section level1">
<h1>Midterm 2</h1>
<div id="instructions" class="section level3">
<h3>Instructions</h3>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.</p></li>
<li><p>Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: <strong>“Does having more funding in a police department lead to fewer incidents of police brutality?”</strong></p></li>
<li><p>Codebook:</p></li>
</ol>
<ul>
<li>funds: How much funding the police department received in that year in millions of dollars.</li>
<li>po.brut: How many incidents of police brutality were reported by the department that year.</li>
<li>po.dept.code: Police department code</li>
</ul>
</div>
<div id="problem-1-eda-10-points" class="section level3">
<h3>Problem 1: EDA (10 points)</h3>
<p>Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.</p>
<pre class="r"><code>dat &lt;- read.csv(file = &#39;sim.data.csv&#39;)
names(dat)</code></pre>
<pre><code>## [1] &quot;po.dept.code&quot; &quot;funds&quot;        &quot;po.brut&quot;</code></pre>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 200   3</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##   po.dept.code        funds          po.brut     
##  Min.   :  1.00   Min.   :21.40   Min.   : 0.00  
##  1st Qu.: 50.75   1st Qu.:51.67   1st Qu.:14.00  
##  Median :100.50   Median :59.75   Median :19.00  
##  Mean   :100.50   Mean   :61.04   Mean   :18.14  
##  3rd Qu.:150.25   3rd Qu.:72.17   3rd Qu.:22.00  
##  Max.   :200.00   Max.   :99.70   Max.   :29.00</code></pre>
<pre class="r"><code>hist(dat$fund)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code>hist(dat$po.brut)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-2.png" width="672" /></p>
<p>This dataset has 200 observations of 3 variables representing 200 police departments identified with a numeral (po.dept.code) with variables describing their yearly funding in millions of dollars (funds) and the number of police brutality incidents reported by the department during this year (po.brut).</p>
<p>Funds: The minimum funding in millions that a department received was 21.4 and the most was 99.7. The mean funding received was 61.04 and the median funding was 59.75.</p>
<p>po.brut: The minimum number of police brutality incidents reported by the department during a year was 0 and the most was 29. The mean number of incidents reported was 18.14 and the median incidents was 19.</p>
<p>The histograms of these variables show a moderetly symmetrical distribution with peaks in the center of the data sets (as shown by the mean and median earlier) and few police departments on either end of the low or high ranges for the variables.</p>
</div>
<div id="problem-2-linear-regression-30-points" class="section level3">
<h3>Problem 2: Linear regression (30 points)</h3>
<ol style="list-style-type: lower-alpha">
<li>Perform a simple linear regression to answer the question of interest. To do this, name your linear model “reg.output” and write the summary of the regression by using “summary(reg.output)”.</li>
</ol>
<pre class="r"><code>reg.output &lt;- lm(dat$po.brut ~ dat$funds, data = dat)
summary(reg.output)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat$po.brut ~ dat$funds, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9433 -0.2233  0.2544  0.5952  1.1803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.543069   0.282503  143.51   &lt;2e-16 ***
## dat$funds   -0.367099   0.004496  -81.64   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9464 on 198 degrees of freedom
## Multiple R-squared:  0.9712, Adjusted R-squared:  0.971 
## F-statistic:  6666 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.</li>
</ol>
<p>The estimated coefficient of the slope is -0.367099 and the estimated coefficient of the intercept is 40.543069.</p>
<p>The standard error is 0.004496.</p>
<p>The p-value is &lt; 2.2e-16.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:</li>
</ol>
<pre class="r"><code>plot(dat$funds, dat$po.brut, main=&quot;Relationship between funds and police brutality&quot;,
    xlab=&quot;Funds in millions&quot;, ylab=&quot;Number of reported cases of police brutality&quot;)
abline(reg.output, col = &quot;red&quot;, lwd=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-41-1.png" width="384" /> Does the line look like a good fit? Why or why not?</p>
<p>The coefficient of determination- as shown here with both the multiple R^2 and the Adjusted R^2 values- are very close to 1 (0.9712 and 0.971), so the regression model accounts for more variance. Additionally, it visually appears to be fairly fitted and even though the tails of the data are a little skewed, overall the line is a good fit.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?</li>
</ol>
<pre class="r"><code>#Linearity Assumption:
plot(dat$funds, reg.output$residuals, main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Funds&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-42-1.png" width="384" /></p>
<pre class="r"><code>plot(reg.output, which=1)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-42-2.png" width="384" /></p>
<pre class="r"><code>#Independence Assumption: using Residuals vs. x plotted above
plot(dat$funds, dat$po.brut, main=&quot;Relationship between funds and police brutality&quot;,
    xlab=&quot;Funds in millions&quot;, ylab=&quot;Number of reported cases of police brutality&quot;)
abline(reg.output, col = &quot;red&quot;, lwd=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-42-3.png" width="384" /></p>
<pre class="r"><code>#Equal Variance Assumption/ Homoscedasticity:
plot(reg.output, which=3)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-42-4.png" width="384" /></p>
<pre class="r"><code>#Normal Population Assumption:
plot(reg.output, which=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-42-5.png" width="384" /></p>
<pre class="r"><code>plot(reg.output, which=5)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-42-6.png" width="384" /></p>
<p>Linearity Assumption: This assumption is not met. The residuals vs. x plot does not have a horizontal direction and does have a significant pattern in the data.</p>
<p>Independence Assumption: This assumption is also not met for the same reason as the linearity assumption as the residuals vs. x plot does not have a horizontal direction and does have a significant pattern in the data and because there does not seem to be a time-series component to the data.</p>
<p>Equal Variance Assumption/ Homoscedasticity: This assumption is not met. While the scatter plot of funds vs. reported police brutality has no apparent tendency for the variations to grow or shrink in any part of the plot, there are significant trends shown by the line in the scale-location plot showing that the errors do not have a constant variance.</p>
<p>Normal Population Assumption: This assumption is not met as the q-q plot has significant left skew deviations for the tail values in this plot.</p>
<p>As these assumptions are not met, if I had more time, I would use the box-cox method to find the best transformation for this data, transform the x variable, and repeat this process.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Answer the question of interest based on your analysis.</li>
</ol>
<p>While the p-value is very small, we cannot conclude that greater funding will reduce incidents of police brutality. None of the four assumptions of linear regressions were satisfied, so we cannot use this model to assess the relationship between these two variables. If this data was transformed and the assumptions could be met with the transformed model, this relationship could be properly assessed.</p>
</div>
<div id="problem-3-data-ethics-10-points" class="section level3">
<h3>Problem 3: Data ethics (10 points)</h3>
<p>Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?</p>
<p>This data set represents 200 police departments with their yearly funding in millions and the departments reported incidents of police brutality. First, it is important to recognize that the police brutality count is only based on what is reported by the department and as police brutality incidents reflect poorly on the department, the department may be under reporting these incidents. This calls into question the fairness of the data as it may not be truly representative of the number of incidents that are actually occurring and could be biased as it is self-reported. Furthermore, with limited information provided by the code book, there is no information about how the sample was collected, requiring the need of assessment for random sampling before utilizing this data for analysis, as well as having no mechanism to redress if people are harmed by the results. However, based on the information provided here, this data set is good in terms of privacy and security as the departments are only represented by a numeric code that has no relation to their identification. Overall, these concerns about the ethics of this dataset call into question the validity of any results from the analysis of this data, as well as concerns about the effect the distribution of these results could have.</p>
</div>
</div>
<div id="assignment-4" class="section level1">
<h1>Assignment 4</h1>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre class="r"><code>#3.2
mpg</code></pre>
<pre><code>## # A tibble: 234 × 11
##    manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class
##    &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;
##  1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…
##  2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…
##  3 audi         a4           2    2008     4 manu… f        20    31 p     comp…
##  4 audi         a4           2    2008     4 auto… f        21    30 p     comp…
##  5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…
##  6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…
##  7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…
##  8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…
##  9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…
## 10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…
## # … with 224 more rows</code></pre>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function creates a basic scatter plot by mapping the aes based on the given x and y variables</code></pre>
<pre class="r"><code>#3.3
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on the previous function by adding a variables color which is class which maps each point to the given variable class type in the dataset mpg

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, size = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-2.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on the 3.2 function by adding a variables size which is class which maps each point to the given variable class type in the dataset mpg, so instead of modify the point&#39;s color, it modifies the literal size of the point in the plot

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-3.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on the 3.2 function by adding a variables alpha which is class which scales the transparency of each point to the given variable class type in the dataset mpg, so instead of modify the point&#39;s color

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-4.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on the 3.2 function by adding a variables shape which is class which maps each point to the given variable class type in the dataset mpg by designated a specific shape to that type, so instead of modify the point&#39;s color, it modifies the literal shape that represents the points class type in the plot

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-45-5.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on the 3.2 function by adding a variables color and manually setting it to the color blue, which makes each point in the plot be displayed with that color</code></pre>
<pre class="r"><code>#3.4
#ggplot(data = mpg) 
#+ geom_point(mapping = aes(x = displ, y = hwy))
# This ggplot function demonstrates a common issue where the + sign has been placed in the wrong spot by placing it at the start of a line instead of the end</code></pre>
<pre class="r"><code>#3.5
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function divides the data into subplots based on the categorical type of class and organizes these subplots into two rows

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ cyl)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-47-2.png" width="672" /></p>
<pre class="r"><code># Conversely, this ggplot function divides the data into subplots based on the combination of two variables- drv and cyl</code></pre>
<pre class="r"><code>#3.6

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<pre class="r"><code># This is the original ggplot function from 3.2

ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-2.png" width="672" /></p>
<pre class="r"><code># This ggplot function transforms the plot into a smooth fitted line for the previous function

ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-3.png" width="672" /></p>
<pre class="r"><code># This ggplot function expands on the previous functions by basing the line type on the variable drv
    
ggplot(data = mpg) +
  geom_smooth(
    mapping = aes(x = displ, y = hwy, color = drv),
    show.legend = FALSE
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-4.png" width="672" /></p>
<pre class="r"><code># This ggplot function expands on the previous functions by both basing the line color instead on the line type on drv and ensuring that a legend will not appear in the plot with this modification

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-5.png" width="672" /></p>
<pre class="r"><code># This ggplot function displays both of the first two ggplot functions from this section on the same plot together

ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-6.png" width="672" /></p>
<pre class="r"><code># This ggplot function is just another way to do what the previous function did- same result

ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-7.png" width="672" /></p>
<pre class="r"><code># This ggplot function expands on the previous functions by creating an aesthetic for only the point plot by setting the color variable to class, which has no effect on the smooth plot as the layer function is localized</code></pre>
<pre class="r"><code>#3.7

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function shows a basic bar graph based on the variable cut and its frequency in the dataset

ggplot(data = diamonds) + 
    stat_count(mapping = aes(x = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-2.png" width="672" /></p>
<pre class="r"><code># This ggplot function has an identical result as the previous function, but is a just different way to complete it

demo &lt;- tribble(
  ~cut,         ~freq,
  &quot;Fair&quot;,       1610,
  &quot;Good&quot;,       4906,
  &quot;Very Good&quot;,  12082,
  &quot;Premium&quot;,    13791,
  &quot;Ideal&quot;,      21551
)

ggplot(data = demo) +
  geom_bar(mapping = aes(x = cut, y = freq), stat = &quot;identity&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-3.png" width="672" /></p>
<pre class="r"><code># These two functions override the standard count function that is a part of the geom_bar function and instead manually designates the values it wants to use

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-4.png" width="672" /></p>
<pre class="r"><code># This ggplot function just expands on the previous function by ordering the x values based on their y values

ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-49-5.png" width="672" /></p>
<pre class="r"><code># This ggplot function expands on the previous function by summarizing the y value for each unique x value to better display the statistical summaries of the data in the plot by demonstrating the min, max, and median values of each x value</code></pre>
<pre class="r"><code>#3.8

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function outlines each of the bars with a unique color to demonstrate its corresponding to a particular cut value

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-2.png" width="672" /></p>
<pre class="r"><code># This ggplot function fills each of the bars with a unique color to demonstrate its corresponding to a particular cut value

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-3.png" width="672" /></p>
<pre class="r"><code># This ggplot function expands on the previous functions and instead of just filling it based on one variable, it fills it based on two, cut and clarity. This fills each section of the bar based on the representative frequency of the other categorical variable it is being combined with

ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = &quot;identity&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-4.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = &quot;identity&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-5.png" width="672" /></p>
<pre class="r"><code># These two ggplots represent the position = &quot;identity&quot; option which eliminates the stacked bar graph nature and instead just places the values exactly where they are in the dataset, however due to overlap, the aesthetic of the plots need to be modified. The first uses a small alpha value so that the sections are slightly transparent and the second used NA so that only the sections are outlined

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;fill&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-6.png" width="672" /></p>
<pre class="r"><code># This ggplot modifies the third function from this section by making each of the stacked bars the same height, which is useful for comparing the size of each section/ proportional distribution

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;dodge&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-7.png" width="672" /></p>
<pre class="r"><code># This ggplot modifies the third function from this section by instead placing each section together horizontally rather than stacking them vertically, which allows for easier comparison for individual values

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = &quot;jitter&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-50-8.png" width="672" /></p>
<pre class="r"><code># This ggplot function modifies the original scatter plot from 3.2 by adding a little bit of noise to each datapoint to avoid overlapping and to better represent the data</code></pre>
<pre class="r"><code>#3.9
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot() +
  coord_flip()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-51-2.png" width="672" /></p>
<pre class="r"><code># The second ggplot function is the same as the first ggplot function here, however the x and y values have been switched in the second one

nz &lt;- map_data(&quot;nz&quot;)
ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = &quot;white&quot;, colour = &quot;black&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-51-3.png" width="672" /></p>
<pre class="r"><code>ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = &quot;white&quot;, colour = &quot;black&quot;) +
  coord_quickmap()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-51-4.png" width="672" /></p>
<pre class="r"><code># The second ggplot function here correctly sets the aspect ratio for the cordinate map creates in the first ggplot function here

bar &lt;- ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)
bar + coord_flip()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-51-5.png" width="672" /></p>
<pre class="r"><code>bar + coord_polar()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-51-6.png" width="672" /></p>
<pre class="r"><code># The first ggplot function here creates a standard bar chart for the data, and then the coordinate flip and coordinate polar functions applied to this bar chart transform it into a coxcomb chart</code></pre>
<pre class="r"><code>#28.2

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(title = &quot;Fuel efficiency generally decreases with engine size&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on simpler forms of this point and smooth plot by adding a plot title with the labs variable

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(
    title = &quot;Fuel efficiency generally decreases with engine size&quot;,
    subtitle = &quot;Two seaters (sports cars) are an exception because of their light weight&quot;,
    caption = &quot;Data from fueleconomy.gov&quot;
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-52-2.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on the previous function by also adding a subtitle and caption within the labs portion

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  labs(
    x = &quot;Engine displacement (L)&quot;,
    y = &quot;Highway fuel economy (mpg)&quot;,
    colour = &quot;Car type&quot;
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-52-3.png" width="672" /></p>
<pre class="r"><code># This ggplot function modifies the previous functions by changing both the x and y axis titles, as well as the legend title

df &lt;- tibble(
  x = runif(10),
  y = runif(10)
)
ggplot(df, aes(x, y)) +
  geom_point() +
  labs(
    x = quote(sum(x[i] ^ 2, i == 1, n)),
    y = quote(alpha + beta + frac(delta, theta))
  )</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-52-4.png" width="672" /></p>
<pre class="r"><code># This ggplot function shows how to use mathmatical exquations instead of word quotes for these label variables</code></pre>
<pre class="r"><code>#28.3

best_in_class &lt;- mpg %&gt;%
  group_by(class) %&gt;%
  filter(row_number(desc(hwy)) == 1)
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_text(aes(label = model), data = best_in_class)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function is very similar to a simple scatter plot with geom_point, however it also adds a label onto certain points based on the parameter given in data, best_in_class

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_label(aes(label = model), data = best_in_class, nudge_y = 2, alpha = 0.5)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-2.png" width="672" /></p>
<pre class="r"><code># This ggplot function extends on the previous function by adding a small box around the text and shifting it slightly higher than the point to make it easier to read

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_point(size = 3, shape = 1, data = best_in_class) +
  ggrepel::geom_label_repel(aes(label = model), data = best_in_class)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-3.png" width="672" /></p>
<pre class="r"><code># This ggplot function extends on the previous function by ensuring that none of the previous labels overlap in the plot

class_avg &lt;- mpg %&gt;%
  group_by(class) %&gt;%
  summarise(
    displ = median(displ),
    hwy = median(hwy)
  )
ggplot(mpg, aes(displ, hwy, colour = class)) +
  ggrepel::geom_label_repel(aes(label = class),
    data = class_avg,
    size = 6,
    label.size = 0,
    segment.color = NA
  ) +
  geom_point() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-4.png" width="672" /></p>
<pre class="r"><code># This set of functions builds on the previous ggplot function by replacing the legend with color coordinating of the labels which serves to seperate the points in the same manner that the legend did

label &lt;- mpg %&gt;%
  summarise(
    displ = max(displ),
    hwy = max(hwy),
    label = &quot;Increasing engine size is \nrelated to decreasing fuel economy.&quot;
  )
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_text(aes(label = label), data = label, vjust = &quot;top&quot;, hjust = &quot;right&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-5.png" width="672" /></p>
<pre class="r"><code># This set of functions creates a label and then inputs it into the top right corner of the plot

label &lt;- tibble(
  displ = Inf,
  hwy = Inf,
  label = &quot;Increasing engine size is \nrelated to decreasing fuel economy.&quot;
)
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_text(aes(label = label), data = label, vjust = &quot;top&quot;, hjust = &quot;right&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-6.png" width="672" /></p>
<pre class="r"><code># This ggplot function extends on the previous function by moving the text all the way into the corner using the Inf parameters

&quot;Increasing engine size is related to decreasing fuel economy.&quot; %&gt;%
  stringr::str_wrap(width = 40) %&gt;%
  writeLines()</code></pre>
<pre><code>## Increasing engine size is related to
## decreasing fuel economy.</code></pre>
<pre class="r"><code># This function is merely used to automatically input line breaks, rather than the manual \n process used in these previous functions</code></pre>
<pre class="r"><code>#28.4

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  scale_x_continuous() +
  scale_y_continuous() +
  scale_colour_discrete()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-2.png" width="672" /></p>
<pre class="r"><code># This second ggplot function demonstrates the manual process of how the scales are automatically set in the first function by the ggplot package

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_y_continuous(breaks = seq(15, 40, by = 5))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-3.png" width="672" /></p>
<pre class="r"><code># This ggplot function overrides the standard breaks and instead manually sets them to be every 5 values between 15-40

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_x_continuous(labels = NULL) +
  scale_y_continuous(labels = NULL)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-4.png" width="672" /></p>
<pre class="r"><code># This ggplot function overrides the standard breaks by removing the lick labels on both the x and y axises

presidential %&gt;%
  mutate(id = 33 + row_number()) %&gt;%
  ggplot(aes(start, id)) +
    geom_point() +
    geom_segment(aes(xend = end, yend = id)) +
    scale_x_date(NULL, breaks = presidential$start, date_labels = &quot;&#39;%y&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-5.png" width="672" /></p>
<pre class="r"><code># This ggplot function overrides the standard breaks by setting the tick values to be exactly where the x values fall in the plot

base &lt;- ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class))
base + theme(legend.position = &quot;left&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-6.png" width="672" /></p>
<pre class="r"><code>base + theme(legend.position = &quot;top&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-7.png" width="672" /></p>
<pre class="r"><code>base + theme(legend.position = &quot;bottom&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-8.png" width="672" /></p>
<pre class="r"><code>base + theme(legend.position = &quot;right&quot;) # the default</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-9.png" width="672" /></p>
<pre class="r"><code># This ggplot function overrides the typically location of the legend and instead shifts it to the left, right, below, and above the plot here

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  theme(legend.position = &quot;bottom&quot;) +
  guides(colour = guide_legend(nrow = 1, override.aes = list(size = 4)))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-10.png" width="672" /></p>
<pre class="r"><code>#&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;
# This ggplot function further modifies the legend by both setting the number of rows that the legend has and by enlarging the size of the points in the legend by using the list size variable

ggplot(diamonds, aes(carat, price)) +
  geom_bin2d()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-11.png" width="672" /></p>
<pre class="r"><code>ggplot(diamonds, aes(log10(carat), log10(price))) +
  geom_bin2d()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-12.png" width="672" /></p>
<pre class="r"><code># This ggplot function shows a transformed scale as the second function uses a log transformation to better represent the relashonship between the variables

ggplot(diamonds, aes(carat, price)) +
  geom_bin2d() + 
  scale_x_log10() + 
  scale_y_log10()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-13.png" width="672" /></p>
<pre class="r"><code># This ggplot function builds on the previuous function by changing the axises to be the origonal, not the transformed, values to better read and interpret the plot

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-14.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv)) +
  scale_colour_brewer(palette = &quot;Set1&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-15.png" width="672" /></p>
<pre class="r"><code># The second ggplot function here slightly changes the color scale used in the first function with the palatte variable, which is useful for perception especially for people with color blindness

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv, shape = drv)) +
  scale_colour_brewer(palette = &quot;Set1&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-16.png" width="672" /></p>
<pre class="r"><code># This ggplot function further modifies the scales by also adding the shape variable to the points which ensures the points are still distiguishable even when displayed in black and white

presidential %&gt;%
  mutate(id = 33 + row_number()) %&gt;%
  ggplot(aes(start, id, colour = party)) +
    geom_point() +
    geom_segment(aes(xend = end, yend = id)) +
    scale_colour_manual(values = c(Republican = &quot;red&quot;, Democratic = &quot;blue&quot;))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-17.png" width="672" /></p>
<pre class="r"><code># This ggplot function how to manually set the color scales for specific variables when the color needs to represent how they typically are classified such as with democrats and republicans with blue and red

df &lt;- tibble(
  x = rnorm(10000),
  y = rnorm(10000)
)
ggplot(df, aes(x, y)) +
  geom_hex() +
  coord_fixed()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-18.png" width="672" /></p>
<pre class="r"><code>ggplot(df, aes(x, y)) +
  geom_hex() +
  viridis::scale_fill_viridis() +
  coord_fixed()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-19.png" width="672" /></p>
<pre class="r"><code># These ggplot functions demonstrate how the color gradient can also be based on the how the point sits in relation to the mean of that variable based on how transparent or the coloring it has is visually percieved</code></pre>
<pre class="r"><code>#28.5

ggplot(mpg, mapping = aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth() +
  coord_cartesian(xlim = c(5, 7), ylim = c(10, 30))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<pre class="r"><code>mpg %&gt;%
  filter(displ &gt;= 5, displ &lt;= 7, hwy &gt;= 10, hwy &lt;= 30) %&gt;%
  ggplot(aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-2.png" width="672" /></p>
<pre class="r"><code># This ggplot function zooms in on the previous function&#39;s plot with the coord_Cartesian and displ variables, which demonstrates that the coord_Cartesian variable is a much better representative plot for the zoomed in portion

suv &lt;- mpg %&gt;% filter(class == &quot;suv&quot;)
compact &lt;- mpg %&gt;% filter(class == &quot;compact&quot;)
ggplot(suv, aes(displ, hwy, colour = drv)) +
  geom_point()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-3.png" width="672" /></p>
<pre class="r"><code>ggplot(compact, aes(displ, hwy, colour = drv)) +
  geom_point()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-4.png" width="672" /></p>
<pre class="r"><code># This ggplot demonstrates how the plot transformes when the x, y, and color scales are are limited or expanded to the same range equal comparission of differnt subportions of the data and plots

x_scale &lt;- scale_x_continuous(limits = range(mpg$displ))
y_scale &lt;- scale_y_continuous(limits = range(mpg$hwy))
col_scale &lt;- scale_colour_discrete(limits = unique(mpg$drv))
ggplot(suv, aes(displ, hwy, colour = drv)) +
  geom_point() +
  x_scale +
  y_scale +
  col_scale</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-5.png" width="672" /></p>
<pre class="r"><code>ggplot(compact, aes(displ, hwy, colour = drv)) +
  geom_point() +
  x_scale +
  y_scale +
  col_scale</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-55-6.png" width="672" /></p>
<pre class="r"><code># These ggplots are simply different ways to achieve the same goal of setting all of the x, y, and color scales to the same range- this can also be achieved with faceting</code></pre>
<pre class="r"><code>#28.6

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  theme_bw()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<pre class="r"><code># This ggplot function sets the theme of the plot- here to white background with grid lines, to one of 8 pre-downloaded themes included in the package</code></pre>
<pre class="r"><code>#28.7

ggplot(mpg, aes(displ, hwy)) + geom_point()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&quot;my-plot.pdf&quot;)
# This ggplot function saves the plot onto the users disk with the current dimensions</code></pre>
</div>
<div id="final-project" class="section level1">
<h1>Final Project</h1>
<p>Investigating the Relationship Between Political Leaning and the Type/Frequency of Criminal Activity on University Campuses Across the United States</p>
<p>Theodora Athanitis, Tori Borlase, Halle Wasser CRIM 250: Statistics for the Social Sciences Dr. Maria Cuellar December 12, 2021</p>
<p>Research Motivation and Question</p>
<p>As college students, the topic of crime on campus is very relevant to us in terms of public safety. Additionally, as all three of us are female students, certain crime types such as those of a violent or sexual nature feel more relevant and concerning. As recent articles in the Daily Pennsylvanian discuss, crime and crime reporting have become more salient to students as classes move back in-person (Perlman, 2021). In light of the return to campus, we feel as though students should be aware of the rates and types of crimes that are most frequent, as well as the factors that impact crime rates on college campuses. Additionally, some studies show that peoples’ perceptions of crime differ depending on their political leanings (Gramlich, 2016). Therefore, our research question is as follows: Does the political leaning (Democratic or Republican) of states affect either the crime type or the frequency of criminal activity on the campuses of public universities in that state? Our question and dataset are interesting because we can 1) help students be more aware of crimes that are highly relevant to them and 2) test whether there is a correlation between political beliefs and actual reported crime, or if future research is necessary to determine if the disparities between crime perceptions are due to other factors. With our analysis, we should be able to shed light on our research question as well as help improve our understanding of topics that are particularly relevant to us. Our hypothesis is that, in states with Republican political leanings, crime will be higher because Republican states may place a greater emphasis on policing and dedicate more resources to monitoring crime.</p>
<p>Exploratory Data Analysis</p>
<p>Description of the Dataset</p>
<p>The UCR Table 9 dataset (“Offenses Known to Law Enforcement by State by University and College”, 2019) is a voluntary reporting collection composed of 569 observations on 14 variables. The variables in the dataset are: state, university.college, Campus, student.enrollment, violent.crime, murder, rape, robbery, aggravated.assault, property.crime, burglary, larceny.theft, motor.vehicle.theft, and arson (please refer to Appendix A for the codebook), with each observation corresponding to an in-state university or college. It is important to note that these observations were not evenly distributed across states; rather, some states had observations for only one in-state university, while others had observations for more than 5.</p>
<p>Missing Values</p>
<p>Within the dataset, there were many missing values for the “arson” variable. This may be because it is a relatively uncommon crime on college campuses; while some institutions chose to denote a lack of arson with “0”, others may have chosen to simply not report a value. There were four states that were not included in the dataset (namely, Alabama, Idaho, Hawaii, and Oregon) because they either did not release complete 12 month data or they did not release any data at all.</p>
<p>Additional Data</p>
<p>For our analysis, we created several new tables to create our EDA plots and to utilize for our linear regressions. The table used for the majority of our analysis is composed of 46 observations on 13 variables, with each observation representing the states with reported data (omitting Alabama, Idaho, Hawaii, and Oregon). The added variables in these datasets are state.leaning (a binary variable that represents the political affiliation the state had in the 2016 presidential election; 0=democratic and 1= republican) and total (an integer variable that is the summation of all crimes committed in the state; i.e., the sum of all crimes in all participating in-state institutions within a state).</p>
<p>Load the data.</p>
<pre class="r"><code>library(readr)
library(knitr)
dat &lt;- read.csv(file = &#39;FinalProjectData.csv&#39;)
dat5 &lt;- read.csv(file = &#39;FinalProjectData5.csv&#39;)</code></pre>
<p>Breakdown of Political Leaning</p>
<p>Within the UCR Dataset, and of the 46 states that reported data about crime on college campuses, we found that a majority were Republican as determined by the 2016 election results. With 28 Republican states and only 18 Democratic ones, this discrepancy is an important consideration given that our analysis compares the differences in crime rates between these two categories of states on average. This means that a smaller number of states skews the average number of crimes generated during the regression analysis significantly, despite relative consistencies in the number of colleges/populations on average between the two political affiliations. The takeaway of this plot is that there were more Republican states than Democratic states reporting; therefore, we should be cognizant that our conclusions may reflect this disparity.</p>
<pre class="r"><code>y = data.frame(Political_Leaning=c(&#39;Republican&#39;, &#39;Democratic&#39;),Number=c(28,18))
colours = c(&quot;red&quot;, &quot;blue&quot;)
w &lt;- c(0.05, 0.05)
barplot(y$Number, width = w, main=&#39;Number of Democratic and Republican
States in the UCR Dataset&#39;, ylab=&#39;Number of States Represented in the UCR Dataset&#39;, xlab=&#39;State Political Affiliation&#39;, names.arg=y$Political_Leaning, col=colours, ylim=c(0,30))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-59-1.png" width="403.2" /></p>
<p>Figure 1. Bar Graph of the Number of Democratic and Republican States in the UCR Table 9 Dataset.</p>
<p>Frequencies of Crime Types</p>
<pre><code>The following bar graph shows the frequencies of different types of crimes reported in both Democratic and Republican states. As shown in Figure 2, there were more crimes in Republican states for all but one category of crime (aggravated assault). However, we should keep in mind that there were significantly more Republican states that reported crime data to the UCR, and that our dataset did not contain information about the population of states, therefore it is difficult to contextualize these results. Based on these differences, we might expect that our model and causal analysis will show that Republican states have higher amounts of crime.</code></pre>
<pre class="r"><code>counts5 &lt;- t(as.matrix(dat5[-1]))
counts5</code></pre>
<pre><code>##    [,1] [,2]  [,3]  [,4] [,5] [,6]  [,7] [,8] [,9] [,10]
## X0 1420  214 47092 22796    2  736 20223 1837   82   646
## X1 1481  211 52346 25404    5  957 22423 2028   58     5</code></pre>
<pre class="r"><code>colnames(counts5) &lt;- dat5$crime_type
colours = c(&quot;blue&quot;, &quot;red&quot;)
barplot(counts5, main=&#39;Frequency of Crime Type by Political Leaning&#39;, ylab=&#39;Count of Criminal Offenses&#39;, xlab=&#39;Crime Type&#39;,beside = TRUE, 
        col=colours, ylim=c(0,max(counts5)*1))

legend(&#39;topright&#39;,fill=colours,legend=c(&#39;Democratic States&#39;,&#39;Republican States&#39;))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-60-1.png" width="1440" /> Figure 2. Bar graph of the number and type of crimes at college campuses in Democratic and Republican states.</p>
<p>Modeling the Data</p>
<p>As a preliminary step in assessing the relationship between the total crime variable and the binary state.leaning variable, we first found the correlation between the two variables to be -0.1245639.</p>
<pre class="r"><code># Correlation between Crime and Political Affiliation
cor(dat$State.Leaning, dat$Total)</code></pre>
<pre><code>## [1] -0.1245639</code></pre>
<p>Despite this negative result, we further explored this relationship by regressing total crime on state.leaning. This analysis found that the average number of crimes on college campuses annually is 5280 total crimes Democratic States and 3767 in Republican States. However, we also found that both the equal variance assumption and the normal population assumption were not met, therefore invalidating this model to assess this relationship with the data in its current form (refer to Appendix B for diagnostic plots).</p>
<pre class="r"><code># Total Crime Regression
reg.output &lt;- lm(dat$Total ~ dat$State.Leaning, data = dat)
summary(reg.output)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat$Total ~ dat$State.Leaning, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4901.4 -3097.1 -1587.2   698.5 30250.6 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           5280       1417   3.726 0.000551 ***
## dat$State.Leaning    -1513       1816  -0.833 0.409484    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6012 on 44 degrees of freedom
## Multiple R-squared:  0.01552,    Adjusted R-squared:  -0.006858 
## F-statistic: 0.6935 on 1 and 44 DF,  p-value: 0.4095</code></pre>
<pre class="r"><code>plot(reg.output)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-1.png" width="576" /><img src="Journal_files/figure-html/unnamed-chunk-62-2.png" width="576" /><img src="Journal_files/figure-html/unnamed-chunk-62-3.png" width="576" /><img src="Journal_files/figure-html/unnamed-chunk-62-4.png" width="576" /></p>
<pre class="r"><code># Linearity Assumption:
plot(dat$State.Leaning, reg.output$residuals, main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Political Leaning&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-5.png" width="576" /></p>
<pre class="r"><code>plot(reg.output, which=1)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-6.png" width="576" /></p>
<pre class="r"><code># Independence Assumption: using Residuals vs. x plotted above
plot(dat$State.Leaning, dat$Total, main=&quot;Relationship between crime and political leaning&quot;,
    xlab=&quot;Political Leaning&quot;, ylab=&quot;Number of criminal offences&quot;)
abline(reg.output, col = &quot;red&quot;, lwd=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-7.png" width="576" /></p>
<pre class="r"><code># Equal Variance Assumption/ Homoscedasticity:
plot(reg.output, which=3)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-8.png" width="576" /></p>
<pre class="r"><code># Normal Population Assumption:
plot(reg.output, which=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-9.png" width="576" /></p>
<pre class="r"><code>plot(reg.output, which=5)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-62-10.png" width="576" /></p>
<p>Linearity Assumption: This assumption is met. The residuals vs. x plot has a horizontal direction and does have a significant pattern in the data. Furthermore, the residuals vs fitted plot is fairly horizontal and flat, meaning that there is no discernible non-linear trend to the residuals.</p>
<p>Independence Assumption: This assumption is also met for the same reason as the linearity assumption as the residuals vs. x plot has a horizontal direction and does have a significant pattern in the data, as well as because there does not seem to be a time-series component to the data.</p>
<p>Equal Variance Assumption/ Homoscedasticity: This assumption is not met. The scatter plot of crimes vs. political affiliation has no variations with shrinkage in the plot. Additionally, there are significant negative trends, based on the size of the data, shown by the line in the scale-location plot showing that the errors do not have a constant variance.</p>
<p>Normal Population Assumption: This assumption is not met since the q-q plot has significant left skew deviations and is heavy-tailed for the values in this plot.</p>
<p>As these assumptions are not met, normally the next step would be to use the box-cox method to find the best transformation for this data, transform the x variable, and repeat this process. However, as the p-value was so large at 0.4095, demonstrating that this relationship is not statistically significant, we instead concluded that we cannot reject the null hypothesis and instead explored whether or not this relationship existed for a particular crime type variable.</p>
<p>For the rape and violent crime regression it was found that the average number of rapes on college campuses in Democratic states is 2616.2 and 1868.5 in Republican states, and the average number of violent crimes in Democratic states is 78.89 and 52.89 for Republican states. Unfortunately, the two variables that we explored also had significant p-values of 0.4116 and 0.2967, respectively, and we therefore concluded that we cannot reject the null hypothesis for these individual variables either.</p>
<pre class="r"><code># Rape regression
reg.output1 &lt;- lm(dat$Rape ~ dat$State.Leaning, data = dat)
summary(reg.output1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat$Rape ~ dat$State.Leaning, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2427.2 -1536.8  -780.4   348.2 14986.8 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         2616.2      702.8   3.723 0.000557 ***
## dat$State.Leaning   -746.7      900.8  -0.829 0.411605    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2982 on 44 degrees of freedom
## Multiple R-squared:  0.01538,    Adjusted R-squared:  -0.007001 
## F-statistic: 0.6872 on 1 and 44 DF,  p-value: 0.4116</code></pre>
<pre class="r"><code># Violent Crime Regression
reg.output2 &lt;- lm(dat$Violent.crime ~ dat$State.Leaning, data = dat)
summary(reg.output2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat$Violent.crime ~ dat$State.Leaning, data = dat)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -77.89 -46.64 -19.39  31.11 417.11 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          78.89      19.20   4.108 0.000171 ***
## dat$State.Leaning   -26.00      24.62  -1.056 0.296690    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 81.48 on 44 degrees of freedom
## Multiple R-squared:  0.02472,    Adjusted R-squared:  0.002556 
## F-statistic: 1.115 on 1 and 44 DF,  p-value: 0.2967</code></pre>
<p>While this analysis does not show a relationship between crime frequency on college campuses and the political affiliation of the state in which it is located, this relationship may exist in an indirect fashion and is not represented in this dataset due to other causal factors that we will discuss in the following sections.</p>
<p>Causal Analysis</p>
<p>Causal Factors</p>
<p>As a reminder, our question of interest was if there was a relationship between state political leaning and crime on college campuses. We selected to not conduct a causal analysis given our low p-values in our regression analysis, especially because many other factors could cause crime to increase or decrease, and we are unable to answer a causal question with observational data. There may be other causal mediators that could change crime on college campuses other than a direct effect of the political leanings of the state in which the college is located. As seen in our DAG below, while there may be a direct relationship between our main variables of interest, political affiliations may also impact police funding, social program funding, reporting standards, and open carry laws (to name a few), which may in turn be the true cause of different crimes and their frequencies. The DAG below shows those relationships, and especially given our low p-values, we should be cautious in making any causal assessments for our specific research question.</p>
<p>Figure 3. Directed Acyclic Graph of the relationship between state political party affiliation, crime type and frequency on campus, and other intermediary factors.</p>
<p>Final Discussion</p>
<p>Overall, our regression analysis failed all but two of the assumption tests as well as returning relatively high p-values. We are unable to reject the null hypothesis that political affiliation of states has no impact on the crime type or frequency on college campuses. When analyzing our DAG, it is important to consider which internal nodes have causal effects and the degree to which these nodes influence the potential for a causal relationship. Although our analysis may suggest that there is no causal relationship between our variables of interest, it is clear that the relationship might still exist. In order to reach a conclusion, a discussion of our method’s limitations is warranted, as well as future research suggestions to avoid similar issues.</p>
<p>Limitations</p>
<p>Along with the limitations discussed above regarding the incomplete reporting data and the inclusion of more Republican states, there are other key limitations that need to be addressed. Firstly, California and Texas were significant outliers given that they not only had the most in-state institutions voluntarily report but the institutions within these states also had larger student enrollments. Given that our regression analysis results show the number of crimes on average, any state/institution with a larger student enrollment would skew the average for each state, shifting the representative sample of the states within each political affiliation group. Another limitation of our method is that we only utilized 2016 election results to assign political alignment rather than placing the state on a spectrum of the percentage of votes for a certain party. Because of this, the state.leaning variable was binary, which might explain why our linear regression model did not satisfy any of the assumptions. While one might question why we chose to keep this variable as binary, rather than switching to a spectrum before completing our analysis, the existence of swing states would have made it difficult to analyze the results. If states were hovering near 50%, it would be difficult to determine the influence of political affiliation on perceptions of crime and policing.</p>
<p>Future Research Recommendations</p>
<p>Although the results of our analysis suggest that a state’s political leaning does not influence the type of frequency of crime on in-state university campuses, this determination is far from sufficient to rule out the possibility of relationship. Based on our study’s limitations, it would be beneficial to analyze three different categories of states: (1) Republican stronghold states, (2) Democratic stronghold states, and (3) swing states. This political breakdown, along with a discussion of the changes in crime rates on college campuses within these states for the year directly following an election may better explain the relationship between political affiliation and crime type and frequency of in-state institutions. Another suggestion would be standardizing the data points collected by looking at crime rates per capita and including population and campus size information such that we are able to compare universities of equal student-enrollment. In other words, data points need to be standardized in order to control for confounding variables, such as the environment (urban vs. rural campus, the campus having its own police force, etc.). Lastly, we would suggest utilizing the campus’ political leaning, rather than the political leaning of the state where the college is located given that these political leanings may conflict, especially in swing states. These method recommendations lend themselves to better answer the research question of interest.</p>
<p>Concluding Remarks</p>
<p>In conclusion, our data analysis showed that there was no statistically significant correlation between state political leaning and crime types and frequencies on college campuses. Given that our data was observational, we were unable to conduct a proper causal analysis, and we hope that future research in this field can further explore both correlation and causal relationships between our two variables of interest.</p>
<p>References</p>
<p>Federal Bureau of Investigation. (2019). 2019 Crime in the United States: Table 9, Offenses Known to Law Enforcement by State by University and College, 2019. U.S. Department of Justice FBI: UCR. <a href="https://ucr.fbi.gov/crime-in-the-u.s/2019/crime-in-the-u.s.-2019/topic-pages/tables/table-9/table-9.xls/view" class="uri">https://ucr.fbi.gov/crime-in-the-u.s/2019/crime-in-the-u.s.-2019/topic-pages/tables/table-9/table-9.xls/view</a>.</p>
<p>Gramlich, J. (2016, November 16). Voters’ perceptions of crime continue to conflict with reality. Pew Research Center. <a href="https://www.pewresearch.org/fact-tank/2016/11/16/voters-perceptions-of-crime-continue-to-conflict-with-reality/" class="uri">https://www.pewresearch.org/fact-tank/2016/11/16/voters-perceptions-of-crime-continue-to-conflict-with-reality/</a>.</p>
<p>Perlman, L. (2021, November 4). 3 crimes, 0 alerts: A look into Penn’s crime reporting system. The Daily Pennsylvanian. <a href="https://www.thedp.com/article/2021/11/penn-alerts-clery-crimes-reporting-system" class="uri">https://www.thedp.com/article/2021/11/penn-alerts-clery-crimes-reporting-system</a>.</p>
<p>Appendix A</p>
<p>Codebook: Variable Names and Relevant Definitions</p>
<pre class="r"><code>#state
#   Full name of the state where the college campus is located
#university.college
#   Full name of college or university
#Campus
#   Individual campus name where applicable- ex. California State University ‘Bakersfield’, if inapplicable a #   value of N/A is inputted
#student.enrollment
#   Integer variable based on 2018 United States Department of Education enrollment reports that includes both     undergraduate and graduate populations where applicable</code></pre>
<p>The following variables are based on the local definition of the crime in the given jurisdiction- the only exceptions are included below.</p>
<pre class="r"><code>#violent.crime
#murder
#   This variable includes both murder and non-negligent manslaughter
#rape
#   This definition is based on the 2017 UCR revised defintion of rape that removes the variable of ‘forcible’     from the classification
#robbery
#aggravated.assault
#property.crime
#burglary
#larceny.theft
#motor.vehicle.theft
#arson</code></pre>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
